<div id="thesis">
    <h1>Embodied music controller</h1>
    <i>Completed in: August 2021 </i>

    <p> For the graduation project of the master interaction technology at the University of Twente, I developed an embodied music controller that makes it possible for producers to perform their material using gestures and movements. This way audio clips and parameters can be triggered and adjusted in a way that feels more satisfying for the performer and more engaging for the audience.   </p> 
        
    <p>I created three wireless devices which transmit data from an IMU sensor to my laptop. the software is able to distinguish between different gestures using machine learning (an RNN LSTM) and is able to send out the corresponding musical information (MIDI) to a DAW</p>

    <p>This system has been co-developed with music producers and dancers. The transparency and engagement of a performance given  with the controller has been evaluated with an audience. Results show that both performers and audience are excited about this technology being used</p>

    <p>For more information you can access the thesis <a style="text-decoration: underline;" href="http://essay.utwente.nl/88241/1/van_Soelen_MA_EEMCS.pdf" target="_blank"> here</a></p>

    <iframe width="100%" height="315" src="https://www.youtube.com/embed/nhJEbcDCL5k" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>
    <p class="work-text">
    </p>
</div>

